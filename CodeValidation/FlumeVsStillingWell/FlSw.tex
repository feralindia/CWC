% Created 2018-02-10 Sat 09:30
% Intended LaTeX compiler: pdflatex
\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{listingsutf8}
\usepackage{minted}
\author{R.S. Bhalla}
\date{\today}
\title{Flume and Velocity Area Comparison}
\hypersetup{
 pdfauthor={R.S. Bhalla},
 pdftitle={Flume and Velocity Area Comparison},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.3.50.2 (Org mode 9.1.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\setcounter{tocdepth}{2}
\tableofcontents



\section*{Summary}
\label{sec:org519a555}

This documents the code written to test the difference between stream discharges measured using the velocity area method and from flumes.
Most of the code is borrowed from the CWC project, with the exception of the code for velocity-area measurements which has been rewritten using the simple feature (sf) library and is now based on functions. 

\section*{Libraries}
\label{sec:org07fa2c1}

The following modules are used:

\begin{enumerate}
\item reshape2
\item ggplot2
\item sf
\end{enumerate}

\section*{Functions}
\label{sec:org627cbc6}

\subsection*{Import Data}
\label{sec:orgfa497ea}

Import wlr data from raw files (multiple files downloaded from loggers) by merging the files together and formatting the time zone and rename the columns.

\begin{description}
\item[{Input}] Full file names, can also be a list of file names generated by list.files()
\item[{Output}] Merged dataset
\end{description}

\begin{minted}[]{r}
importdata <- function(flnm){
  x <- do.call("rbind", lapply(flnm, read.csv, skip=8, header=FALSE, strip.white = TRUE, blank.lines.skip = TRUE, stringsAsFactors = FALSE))
  names(x)<- c("scan", "date", "time", "capacitance", "stage")
  x <- x[!is.na(x$date),]
  x$date <- as.Date(x$date, format = "%d/%m/%Y") 
  x <- transform(x, timestamp = paste(date, time, sep=' '))
  x <- x[!is.na(x$date),]
  x$timestamp <- as.POSIXct(x$timestamp, tz = "Asia/Kolkata")
  return(x)
}
\end{minted}

\subsection*{Calibration of capacitance probe}
\label{sec:org27a369a}

The probe comprises of two parts: a brass weight which is about 5 cm long and  \textbf{shows no capacitance increase} along its length, and a teflon coated wire which shows a linear increase in capacitance as it is submerged. We tested whether it made any difference in the calculation of the stage if we changed the type of model fit to the length of the wire. 

\subsubsection*{getlm}
\label{sec:org231635d}

This uses a linear model to calibrate the capacitance probe. The function does a quick check to see if measurements are entered in cm or metres and ensures the reading are in metres.

\begin{description}
\item[{Input}] Name of file holding the calibration reading.
\item[{Output}] Summary of model
\end{description}

\begin{minted}[]{r}
getlm <- function(x){
  calibdat <- read.csv(x, header=FALSE, sep=",", col.names=c("stage", "capacitance"), skip=6)
  if(max(calibdat$stage, na.rm = TRUE) > 5) calibdat$stage <- calibdat$stage/100 # convert to meters when calibration is done in cm
  fitlm <- lm(stage ~ capacitance, data = calibdat)
  print(tail(calibdat))
  print(summary(fitlm))
  return(fitlm) 
}
\end{minted}

\subsubsection*{getlm.brass}
\label{sec:org416c630}

This uses a interaction linear model to calibrate the capacitance probe where the interaction term is the material (brass or teflon).

\begin{description}
\item[{Input}] Name of file holding the calibration reading.
\item[{Output}] Summary of model
\end{description}

\begin{minted}[]{r}
getlm.brass <- function(x){
  calibdat <- read.csv(x, header=FALSE, sep=",", col.names=c("stage", "capacitance"), skip=6)
  if(max(calibdat$stage, na.rm = TRUE) > 5) calibdat$stage <- calibdat$stage/100 # convert to meters when calibration is done in cm
  calibdat$material[calibdat$stage>0.055] <- "Teflon"
  calibdat$material[calibdat$stage<=0.055] <- "Brass"
  fitlm <- lm(stage ~ capacitance*material, data = calibdat)
  cutoff<<-min(calibdat$capacitance[calibdat$material=="Teflon"])
  print(tail(calibdat))
  print(summary(fitlm))
  return(fitlm)
}
\end{minted}

\subsubsection*{do.wlr.cal}
\label{sec:org1897c98}

Calibrate the wlr capacitance to stage using the calibration done.

\begin{description}
\item[{Input}] The results of the \texttt{getlm} function above and the wlr data imported using the \texttt{importdata} function.
\item[{Output}] A stagecalc column with calibrated stage values is added to the wlr data.
\item[{TBD}] The calibration needs to be done based on dates so that values are updated over the years to account for changes or degradation of the capacitance probes.
\end{description}

\subsection*{Calculation of discharge for water level recorders placed in stream beds using velocity area method.}
\label{sec:org3565a35}

\subsubsection*{Generate a shapefile to visualise output}
\label{sec:org72ee09d}

Rewrites the matrix of coordinates into a well-known-text file so it can be exported to a shapefile. This function is called by the \texttt{vel.area} function which follows.

\begin{description}
\item[{Input}] Matrix of coordinates of the rectangle as \texttt{x} and the number of rectangles the cross section of the stream is split into as \texttt{y}.
\item[{Output}] ESRI shapefile
\end{description}

\begin{minted}[]{r}
draw.polymatrix <- function(x,y){
  rec1 <- list(x)
  rec1 <- st_polygon(rec1)
  rec1.st <- st_as_sfc(st_as_text(rec1))
  st_write(rec1.st, paste0(y, ".shp"), driver = "ESRI Shapefile", delete_dsn= TRUE)
}
\end{minted}

\subsubsection*{Do the velocity area calculations to generate a rating curve}
\label{sec:org4e0894a}

Calculate the surface area and multiply it by the velocity measurements taken in different sections of the stream. The function reads in the coordinates of the cross section, splits them into sections based on the number of velocity readings taken, calculates their area and multiplies the surface area of each section with the velocity measured to arrive at the \texttt{discharge} part of the calculation. 

\begin{description}
\item[{Input}] \texttt{x} is the list of cross section files and \texttt{y} is the list of velocity measurements. Note: both \texttt{x} and \texttt{y} MUST have the same filename.
\item[{Output}] Shapefiles with names corresponding to the input file names corresponding to the cross section and the three divisions (rectangles) where the velocity was measured.
\item[{TBD}] This needs to be changed so that only the intersection is plotted.
\end{description}

\begin{minted}[]{r}
vel.area <- function(x, y){
  if(basename(x)==basename(y)){
     crd <- read.csv(x, header = TRUE, skip = 5)[,-1]
     vel <- read.csv(y, header = TRUE, skip = 5)
     obs.file <- gsub(".csv| ", "", basename(x))
     site <- strsplit(x, split="/")[[1]][11]
     print(paste0(site, ": ", obs.file))
     out.nm <- paste0(sd.res.dir, site, "_", obs.file)
     crd <- crd/100 # convert to metres
     if(crd[1,1] != 0 | crd[1,2] != 0) crd <- rbind(c(0,0),crd) ## add row of 0,0 if missing
     crd <- rbind(crd, c(0,0))
     ## crd <- rbind(crd, crd[1,])
     crd[ , 2] <- crd[ , 2]*-1 # covert y values to negative (depth)
     crd.mat <- as.matrix(crd)
     xsec <- st_polygon(list(crd.mat))
     xsec.st <- st_as_sfc(st_as_text(xsec)) # convert to wkt then sfc
     st_write(xsec.st, paste0(out.nm, "crossec.shp"), driver = "ESRI Shapefile", delete_dsn= TRUE) # write to shapefile        
     ## st_area(xsec)
     plot(xsec)
     divs <- length(unique(gsub("[[:digit:]]", "", vel$Sl.No.))) # number of divisions of xsec
     seg.ln <- max(crd$Length, na.rm = T)
     seg.ht <- min(crd$Depth, na.rm = T)
     bbx <- paste(seq(0, seg.ln, length.out = divs+1), seg.ht, sep = ",")
     cl1 <- seq(0, seg.ln, length.out = divs+1)
     cl2 <- rep(seg.ht,divs+1)
     bbx <- matrix(c(cl1,cl2), nrow=length(cl1))
     st <- seq(1, nrow(bbx)-1, by=1)
     rec <- lapply(st, function(x){
       y <- x+1
       r1 <- bbx[x,]
       r2 <- bbx[y,]
       r3 <- cbind(bbx[y,1], 0)
       r4 <- cbind(bbx[x,1], 0)
       r5 <- bbx[x,]
       return(rbind(r1,r2,r3, r4, r5))
     })
     rec.ln <- paste0(out.nm, "RecNo_",1:length(rec)) # suffix of shapefile
     mapply(draw.polymatrix, rec, rec.ln) # export to shapefile        
     sx.area <- lapply(rec, function(x){ # calculate area of rec and xsec
       pol <- st_polygon(list(x))
       int <- st_intersection(xsec, pol)
       return(st_area(int))
     })
     vel$secno <- gsub("[[:digit:]]", "", vel$Sl.No.)
     vel <- aggregate(cbind(velR1, velR2, velR3) ~ secno, data=vel, FUN=mean)
     avg.vel <- as.list(apply(vel,1, function(x) mean(as.numeric(x[2:4]))))
     avg.disch <- sum(mapply(prod, sx.area, avg.vel)) # multiply each velocity with each xsec and add
     xsec.depth.m <- seg.ht*-1
     ## get timestamp of velocity readings
     vel.dt <- as.Date(read.csv(y, skip=1,nrows=1, header=F)[,c(2)], format = "%d/%m/%y")
     vel.tm <- read.csv(y, skip=2,nrows=1, header=F)[,c(2)]
     vel.dt.tm <- paste(vel.dt, vel.tm, sep=' ')
     timestamp <- as.POSIXct(vel.dt.tm, format="%Y-%m-%d %I:%M:%S %p", tz="Asia/Kolkata") 
     res.df <- data.frame(site, obs.file, timestamp, avg.disch, xsec.depth.m)
     return(res.df)
     } else {
     print("ERROR: File names differ.")
   }
}
\end{minted}

\subsubsection*{Get the stage of the stream recorder based on time stamp of velocity measurements}
\label{sec:org979aa31}

The stage of the water level recorder is then taken from the timestamp on the velocity measurement and used as the \texttt{stage} part of the calculation. 

\begin{description}
\item[{Input}] \texttt{x} is the output of the \texttt{vel.area} function; \texttt{y} is the calibrated wlr readings at 15 minute intervals. This can be changed to a five minute interval (or any other) if needed.
\item[{Output}] Stage appended to the stage discharge file which can now be used to calculate the rating curve.
\end{description}

\begin{minted}[]{r}
get.stage <- function(x, y){
  sd <- read.csv(x)
  sd$timestamp <- as.POSIXct(sd$timestamp, tz = "Asia/Kolkata")
  wlr <- read.csv(y)
  wlr$date_time <- as.POSIXct(wlr$date_time, tz = "Asia/Kolkata")
  sd$dt.round <- as.POSIXct(round(as.double(sd$timestamp)/(15*60))*(15*60),origin=(as.POSIXct('1970-01-01')))
  wlr$dt.round <- as.POSIXct(round(as.double(wlr$date_time)/(15*60))*(15*60),origin=(as.POSIXct('1970-01-01')))
  merged.df <- merge(sd, wlr, by = "dt.round")
  merged.df <- merged.df[complete.cases(merged.df),]
  merged.df <- merged.df[,c(-1, -2, -8, -12)]
  names(merged.df) <- c("site", "obs.file", "vel.timestamp", "avg.disch", "xsec.depth", "scan", "stage", "wlr.timestamp")
  return(merged.df)
}
\end{minted}

\subsubsection*{Calculate discharges using velocity area method}
\label{sec:orgf03fe88}

Calculates discharge based on the nonlinear (weighted) least-squares estimates of the rating data.

\begin{description}
\item[{Input}] Stilling well data processed using the "importdata" function as x and rating curve data calculated using the vel.area function as y.
\item[{Output}] Discharge values for the wlr data. 

\begin{minted}[]{r}
calc.disch.areastage <- function(x, y){
  sd <- read.csv(y) # "~/Res/CWC/Data/Nilgiris/cleaned.rating/csv/WLR_107_SD.csv")
  sd <- sd[,c("stage", "avg.disch")]
  names(sd) <- c("Stage", "Discharge")
  nls.res <- nls(Discharge~p1*Stage^p3, data=sd, start=list(p1=3,p3=5), control = list(maxiter = 500)) # (p1=3,p3=5)
  coef.p1 <- as.numeric(coef(nls.res)[1])
  coef.p3 <- as.numeric(coef(nls.res)[2])
  x <- x[, c("capacitance", "stagecalc", "timestamp")]
  names(x) <- c("Capacitance", "Stage", "Timestamp")
  x$Discharge <- coef.p1*x$Stage^coef.p3
  return(x)
}
\end{minted}
\end{description}

\subsection*{Calculation of discharge for flume}
\label{sec:orga23a749}

\subsubsection*{Fix stage of flume}
\label{sec:orgb9b6f82}

The stilling well of the flume is lower than the scale (surface of the flume) by about 6 to 7 cm. This function uses the manual scale readings and compares them to the wlr records following which it adjusts all wlr readings by adding the difference. Note that these values change each time the unit is re-installed and hence this code needs to be re-run each year using the appropriate set of readings.

\begin{description}
\item[{input}] File with manual readings from the stilling well and the flume data with stage calculated.
\item[{Output}] Adjusted stage in the flume file.
\end{description}

\begin{minted}[]{r}
fix.flume.stage <- function(x, y){
  dat <- read.csv(x)
  dat$Height <- dat$Height/100 # convert to metres
  dat$Timestamp <- as.POSIXct(dat$Timestamp, tz = "Asia/Kolkata", format = "%d/%m/%y %H:%M")
  dat$dt.round <- as.POSIXct(round(as.double(dat$Timestamp)/(15*60))*(15*60),origin=(as.POSIXct('1970-01-01')))
  y$dt.round <- as.POSIXct(round(as.double(y$timestamp)/(15*60))*(15*60),origin=(as.POSIXct('1970-01-01')))
  merged <- merge(y, dat, by = "dt.round")
  merged$stgfix <- merged$stagecalc-merged$Height
  avg.fix <- mean(merged$stgfix, na.rm = TRUE)
  y$stagecalc <- y$stagecalc-avg.fix
  return(y[,-8])
}    
\end{minted}

\subsubsection*{Calculate discharge for the flume}
\label{sec:org3556260}

Uses the equation here \href{https://www.openchannelflow.com/flumes/montana-flumes/discharge-tables}{here} to calculate the discharge from the flume based on the stage readings. Note that all flumes require that the stage is adjusted before this calculation is done using the function \texttt{fix.flume.stage}.

\begin{description}
\item[{Input}] Wlr data for flume generated using the \texttt{importdata} and applying the linear model using the \texttt{predict} function or read in from a file.
\item[{Output}] Discharge values slapped onto the flume data as an additional column.
\end{description}

\begin{minted}[]{r}
calc.disch.flume <- function(x){
  x <- x[,c("capacitance", "stagecalc", "timestamp")]
  names(x) <- c("Capacitance", "Stage", "Timestamp")
  p1 <- 176.5
  p3 <- 1.55
  x$Discharge <- p1*(x$Stage)^p3*0.001 # in m cube per sec
  return(x)
}
\end{minted}

\section*{Testing with sample data}
\label{sec:org1d20087}

All the relevant data is provided as a zip file. It would be very helpful if manual calculations are used to confirm the script works correctly. I have already done this but may have mucked up the formulae/procedure. Stations 107 (grassland velocity-area) and 110 (grassland flume) are being used.

\subsection*{Datasets}
\label{sec:org081cbc6}

\begin{enumerate}
\item Check to see if datasets exist, else unzip the data file and create the datasets. Note that for sake of file size, only a sample of the dataset has been provided.

\begin{minted}[]{r}
setwd("./")
if(!dir.exists("./Data"))unzip("DataSets.zip")
\end{minted}

\item Define file locations

\begin{minted}[]{r}
input.dir <- "./Data/input/"
output.dir <- "./Data/output/"
\end{minted}
\end{enumerate}

\subsection*{Calculate the stage using linear models}
\label{sec:orga413899}

\begin{enumerate}
\item Import the data collected by the water level recorders in a list.

\begin{minted}[]{r}
in.wlr.dir <- list.dirs(paste0(input.dir, "wlr"), recursive = FALSE)
in.wlr.files <- lapply(in.wlr.dir, list.files, full.names = TRUE)
names(in.wlr.files) <- basename(in.wlr.dir)
stillwell <- lapply(in.wlr.files, importdata)
head(stillwell[[1]])
\end{minted}

\begin{verbatim}
  scan       date     time capacitance stage           timestamp
1    1 2013-08-25 15:44:08        2170  2170 2013-08-25 15:44:08
2    2 2013-08-25 15:59:08        2114  2114 2013-08-25 15:59:08
3    3 2013-08-25 16:14:08        2109  2109 2013-08-25 16:14:08
4    4 2013-08-25 16:29:08        2104  2104 2013-08-25 16:29:08
5    5 2013-08-25 16:44:08        2093  2093 2013-08-25 16:44:08
6    6 2013-08-25 16:59:08        2091  2091 2013-08-25 16:59:08
\end{verbatim}

\item Calibrate the relevant capacitance probes and calculate the stages of the wlr readings.

\begin{minted}[]{r}
in.cal.files <- list.files(paste0(input.dir, "calib"), full.names = TRUE)
lm.stillwell <- lapply(in.cal.files, getlm)
names(lm.stillwell) <- basename(in.wlr.dir)
stillwell <- mapply(do.wlr.cal, lm.stillwell, stillwell, SIMPLIFY = FALSE)
head(stillwell[[2]])
\end{minted}

\begin{verbatim}
   stage capacitance
85  0.01        1929
86  0.01        1930
87  0.01        1928
88  0.00        1877
89  0.00        1878
90  0.00        1878

Call:
lm(formula = stage ~ capacitance, data = calibdat)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.040804 -0.007034 -0.000744  0.008371  0.036727 

Coefficients:
	      Estimate Std. Error t value Pr(>|t|)    
(Intercept) -2.720e+00  4.200e-03  -647.6   <2e-16 ***
capacitance  1.436e-03  1.387e-06  1034.9   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.01444 on 88 degrees of freedom
Multiple R-squared:  0.9999,	Adjusted R-squared:  0.9999 
F-statistic: 1.071e+06 on 1 and 88 DF,  p-value: < 2.2e-16

   stage capacitance
67 0.001         599
68 0.001         599
69 0.001         599
70 0.000         589
71 0.000         589
72 0.000         590

Call:
lm(formula = stage ~ capacitance, data = calibdat)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.035865 -0.015188 -0.000074  0.017906  0.033289 

Coefficients:
	      Estimate Std. Error t value Pr(>|t|)    
(Intercept) -3.604e-01  7.666e-03  -47.02   <2e-16 ***
capacitance  6.633e-04  8.704e-06   76.20   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.02215 on 70 degrees of freedom
Multiple R-squared:  0.9881,	Adjusted R-squared:  0.9879 
F-statistic:  5807 on 1 and 70 DF,  p-value: < 2.2e-16
Error in match.fun(FUN) : object 'do.wlr.cal' not found
  scan       date     time capacitance stage           timestamp
2    1 2014-01-09 12:10:16         879  0.14 2014-01-09 12:10:16
3    2 2014-01-09 12:25:16         879  0.14 2014-01-09 12:25:16
4    3 2014-01-09 12:40:16         879  0.14 2014-01-09 12:40:16
5    4 2014-01-09 12:55:16         878  0.14 2014-01-09 12:55:16
6    5 2014-01-09 13:10:16         877  0.14 2014-01-09 13:10:16
7    6 2014-01-09 13:25:16         876  0.14 2014-01-09 13:25:16
\end{verbatim}

\item Correct the flume stage values based on manual measurements. Given that the flume data is in a list, we need to update only the relevant elements of the list. The results of the second code block should be different from the first.

\begin{minted}[]{r}
stillwell[[2]] <- fix.flume.stage(paste0(input.dir, "flume_stage_correction/wlr_110.csv"), stillwell[[2]])
head(stillwell[[2]])
\end{minted}

\begin{verbatim}
Error in `$<-.data.frame`(`*tmp*`, "stgfix", value = numeric(0)) : 
  replacement has 0 rows, data has 14
  scan       date     time capacitance stage           timestamp
2    1 2014-01-09 12:10:16         879  0.14 2014-01-09 12:10:16
3    2 2014-01-09 12:25:16         879  0.14 2014-01-09 12:25:16
4    3 2014-01-09 12:40:16         879  0.14 2014-01-09 12:40:16
5    4 2014-01-09 12:55:16         878  0.14 2014-01-09 12:55:16
6    5 2014-01-09 13:10:16         877  0.14 2014-01-09 13:10:16
7    6 2014-01-09 13:25:16         876  0.14 2014-01-09 13:25:16
\end{verbatim}
\end{enumerate}

\subsection*{Calculate the discharges}
\label{sec:orgcee8e38}

\subsubsection*{For area stage}
\label{sec:org208d09e}

\begin{enumerate}
\item Define the input data sources. Note that the names of the files in the cross section (xsec) and velocity (vel) folder should be exactly the same. As per convention, these are the dates on which the velocity reading was taken.

\begin{minted}[]{r}
in.xsec.dir <- list.dirs(paste0(input.dir, "xsec"), recursive = FALSE)
xsec.fls <- lapply(in.xsec.dir, list.files, full.names = TRUE)
in.vel.dir <- list.dirs(paste0(input.dir, "vel"), recursive = FALSE)
vel.fls <- lapply(in.vel.dir, list.files, full.names = TRUE)
\end{minted}
\end{enumerate}



\noindent\rule{\textwidth}{0.5pt}
\end{document}
